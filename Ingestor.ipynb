{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98342a3e-efe7-4e93-8094-9ac8eab3197f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# first run (21/03/2025)\n",
    "- year 2009\n",
    "- one base existing in this year, each month around 500mb with 8 minutes total time\n",
    "- Using 1 Driver 14 GB Memory, 4 Cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dca61318-f3d9-4e42-9d81-7258cb42e318",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import requests\n",
    "from retry import retry\n",
    "from datetime import datetime\n",
    "\n",
    "# Define parameters\n",
    "years = list(range(2009, 2015))  # From 2009 to 2025\n",
    "months = [f\"{m:02d}\" for m in range(1, 13)]  # 01 to 12\n",
    "trip_types = [\"yellow\", \"green\", \"fhv\", \"fhvhv\"]\n",
    "\n",
    "# Generate URLs dynamically and create a dictionary\n",
    "base_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/\"\n",
    "url_dict = {f\"staging/{trip}/{year}/{month}/{trip}_tripdata_{year}-{month}.parquet\": \n",
    "            f\"{base_url}{trip}_tripdata_{year}-{month}.parquet\"\n",
    "            for year in years for month in months for trip in trip_types}\n",
    "\n",
    "# Define your storage account details\n",
    "storage_account_name = 'lagodedadosalttab'\n",
    "storage_account_key = ''\n",
    "container_name = 'lagodedadosv1'\n",
    "\n",
    "# Create a BlobServiceClient\n",
    "blob_service_client = BlobServiceClient(account_url=f\"https://{storage_account_name}.blob.core.windows.net\", credential=storage_account_key)\n",
    "\n",
    "# Function to upload file with retries\n",
    "@retry(tries=3, delay=2)\n",
    "def upload_file(blob_client, file_data):\n",
    "    blob_client.upload_blob(file_data, overwrite=True)\n",
    "\n",
    "for blob_name, file_url in url_dict.items():\n",
    "    try:\n",
    "        # Check if the blob already exists\n",
    "        blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "        if blob_client.exists():\n",
    "            print(f\"Blob {blob_name} already exists. Skipping download and upload.\")\n",
    "            continue\n",
    "        # Download the file from the URL\n",
    "        response = requests.get(file_url)\n",
    "        # Check HTTP response status\n",
    "        if response.status_code != 200:\n",
    "            raise Exception(f\"Failed to download {file_url}: HTTP {response.status_code}\")\n",
    "        \n",
    "        file_data = response.content\n",
    "        \n",
    "        # Validate file content (simple check for XML error message)\n",
    "        if b\"<Error>\" in file_data:\n",
    "            print(\"teste\")\n",
    "            print(\"Failed to get data from {file_url}: XML error message found. The file does not exists or the url given is invalid.\")\n",
    "            raise Exception(f\"Downloaded file contains error message: {file_data.decode('utf-8')}\")\n",
    "        \n",
    "        upload_file(blob_client, file_data)\n",
    "        print(f\"Uploaded {blob_name} successfully.\")\n",
    "    except Exception as e:\n",
    "        error_message = f\"Failed to upload {blob_name}: {str(e)}\\n\"\n",
    "        print(error_message)\n",
    "        \n",
    "        # Create a unique log file name with the current date and time\n",
    "        current_time = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        log_blob_name = f\"staging/logs/upload_errors_{blob_name}_{current_time}.log\"\n",
    "        log_blob_client = blob_service_client.get_blob_client(container=container_name, blob=log_blob_name)\n",
    "        \n",
    "        # Prepare log content\n",
    "        log_content = f\"Error: {str(e)}\\nURL: {file_url}\\n\"\n",
    "        \n",
    "        # Append the error message to the log file in Azure Blob Storage\n",
    "        log_blob_client.upload_blob(log_content, overwrite=True)\n",
    "\n",
    "print(\"File upload process completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4b6f163-e2a8-4168-88ec-85b6778f4d96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Next steps: \n",
    "\n",
    "- Hide secret key as env variable\n",
    "- parametrize everything\n",
    "- create utils ntb\n",
    "- improve ingestion speed (parallelize)\n",
    "- add meta data"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Ingestor",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
